{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb84b857-2240-4cfd-bb32-82aa788121de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries that we need to process the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a565695f-58f0-4aa9-8eef-a56a46d50f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing EB 1Hour Notraffic Traffic Counts 1 January-30 September,2024.zip: ['Turning Movement Counts - 1 hour bins.csv']\n",
      "Intersection Name: Central & EB580\n",
      "Appended data from Turning Movement Counts - 1 hour bins.csv\n",
      "Processing NB 1Hour Notraffic Traffic Counts 1 January-30 September,2024.zip: ['Turning Movement Counts - 1 hour bins.csv']\n",
      "Intersection Name: Central & EB580\n",
      "Appended data from Turning Movement Counts - 1 hour bins.csv\n",
      "Processing SB 1 Hour Notraffic Traffic Counts 1 January-30 September,2024.zip: ['Turning Movement Counts - 1 hour bins.csv']\n",
      "Intersection Name: Central & EB580\n",
      "Appended data from Turning Movement Counts - 1 hour bins.csv\n",
      "Processing WB 1 Hour Notraffic Traffic Counts 1 January-30 September,2024.zip: ['Turning Movement Counts - 1 hour bins.csv']\n",
      "Intersection Name: Central & EB580\n",
      "Appended data from Turning Movement Counts - 1 hour bins.csv\n",
      "Data saved to Z:/D4/Continuous Counts/Bicycle Location ID/Central & EB580/2024/Turning_volume_agg_Central & EB580.csv\n"
     ]
    }
   ],
   "source": [
    "# Show the path for folder where zip file is sitting\n",
    "zip_directory = r'Z:\\D4\\Continuous Counts\\Bicycle Location ID\\Central & EB580\\2024'\n",
    "\n",
    "# lets create a bucket where we will drop the processed data\n",
    "aggregated_data = []\n",
    "\n",
    "# Iterate over each ZIP file in the directory\n",
    "for zip_filename in os.listdir(zip_directory):\n",
    "    if zip_filename.endswith('.zip'): \n",
    "        zip_path = os.path.join(zip_directory, zip_filename)\n",
    "\n",
    "        try:\n",
    "            # Open the ZIP file\n",
    "            with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "                # List all files inside the ZIP\n",
    "                file_list = z.namelist()\n",
    "\n",
    "                # Filter CSV files that match the prefix\n",
    "                target_files = [f for f in file_list if f.startswith('Turning Movement Counts - 1 hour bins.csv')]\n",
    "                print(f\"Processing {zip_filename}: {target_files}\")\n",
    "\n",
    "                # Process each matching CSV file\n",
    "                for file_name in target_files:\n",
    "                    try:\n",
    "                        with z.open(file_name) as f:\n",
    "                            # We will read the first 6 rows to extract metadata\n",
    "                            metadata = []\n",
    "                            for _ in range(6):  # Read the first 6 rows as metadata\n",
    "                                line = f.readline().decode('utf-8').strip()\n",
    "                                metadata.append(line)\n",
    "                            #print(\"Metadata:\")\n",
    "                            #print(metadata)\n",
    "\n",
    "                            # Extract Intersection Name\n",
    "                            intersection_name = None\n",
    "                            for line in metadata:\n",
    "                                if '\"Intersection Name\"' in line:\n",
    "                                    intersection_name = line.split(',')[1].strip('\"')\n",
    "                                    break\n",
    "                            print(f\"Intersection Name: {intersection_name}\")\n",
    "\n",
    "                            # lets reset the file pointer to the beginning\n",
    "                            f.seek(0)\n",
    "\n",
    "                            # Read the actual data starting from row 7 (header row)\n",
    "                            bdata = pd.read_csv(f, skiprows=7, nrows=6574, delimiter=',')  \n",
    "                            #print(\"Data:\")\n",
    "                            #print(bdata.head())\n",
    "\n",
    "                            # Clean column names\n",
    "                            bdata.columns = bdata.columns.str.strip()\n",
    "\n",
    "                            # Add metadata to the DataFrame\n",
    "                            bdata['Intersection Name'] = intersection_name\n",
    "\n",
    "                            # Convert Date column to datetime format\n",
    "                            bdata['Date'] = pd.to_datetime(bdata['Date'], errors='coerce')\n",
    "\n",
    "                            # Store the data\n",
    "                            aggregated_data.append(bdata)\n",
    "                            print(f\"Appended data from {file_name}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {file_name} in {zip_filename}: {str(e)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening ZIP file {zip_filename}: {str(e)}\")\n",
    "\n",
    "# Concatenate all processed data\n",
    "if aggregated_data:\n",
    "    result_df = pd.concat(aggregated_data, ignore_index=True)\n",
    "    # Rename the duplicate \"Pedestrians\" columns with direction labels\n",
    "    pedestrian_cols = [\"Southbound_Pedestrian\", \"Westbound_Pedestrian\", \"Northbound_Pedestrian\", \"Eastbound_Pedestrian\"]\n",
    "    \n",
    "    # Find the indices of the \"Pedestrians\" columns\n",
    "    pedestrian_indices = [i for i, col in enumerate(result_df.columns) if col == \"Pedestrians\"]\n",
    "    \n",
    "    # Rename them based on their positions\n",
    "    for i, idx in enumerate(pedestrian_indices):\n",
    "        result_df.columns.values[idx] = pedestrian_cols[i]\n",
    "        # Generate a filename using the intersection name\n",
    "    intersection_name = result_df['Intersection Name'].iloc[0] if 'Intersection Name' in result_df.columns else \"Unknown\"\n",
    "    output_path = f'Z:/D4/Continuous Counts/Bicycle Location ID/Central & EB580/2024/Turning_volume_agg_{intersection_name}.csv'\n",
    "    \n",
    "    # Save to CSV with the intersection name in the filename\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Data saved to {output_path}\")\n",
    "else:\n",
    "    print(\"No valid files were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16003068-09ff-43bb-bf17-bb027223a629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'SBUT', 'SBLT', 'SBTH', 'SBRT', 'Pedestrians', 'Total',\n",
       "       'WBUT', 'WBLT', 'WBTH', 'WBRT', 'Pedestrians', 'Total', 'NBUT', 'NBLT',\n",
       "       'NBTH', 'NBRT', 'Pedestrians', 'Total', 'EBUT', 'EBLT', 'EBTH', 'EBRT',\n",
       "       'Pedestrians', 'Total', 'Intersection Name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2caa329-9a5e-41bb-a392-6aa96c5d1821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
